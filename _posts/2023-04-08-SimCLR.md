---
layout: single
title:  "BYOL"
categories: DL
tag: [Deeplearning, Self-supervised learning]
toc: true
use_math: true
typora-root-url: ../
sidebar:
  nav: "counts"
---

**본 게시글은 개인적인 공부를 위해서 작성된 글이니 비약적인 내용 또는 틀린 내용이 포함되어 있을 수 있습니다**

# SimCLR

## Background
1. Generative Learning
    1. Image as label (image 자체를 label로 활용함)
    2. AutoEncoder처럼, Decoder를 활용하여 학습을 진행함. Encoder 부분에서 학습되는 Representation을 위해서 Decoder가 필요하게 되므로 Computational cost가 큼.
    3. 더불어, Context Encoder도 마찬가지로 이미지의 일정한 부분을 잘라내고, 잘라낸 부분을 Encoder와 Decoder를 활용하여 다시 재구성하게 됨. 그리고 잘라낸 부분(GT) 은 알고 있기 때문에 같아지도록 학습을 진행할 수 있음.

2. Proxy task learning
    1. self-made label by proxy task
    2. Decoder없이, Proxy task를 미리 설계하여, Unlabeled data에 Proxy label을 생성함.
    3. 이 때, Proxy task는 사용자가 직접 설계해줘야하는 부분이 있기 때문에 학습 과정에서 더 고차원적인 정보가 학습되는지 불명확함.
    4. Decoder 없이 SSL이 가능하다는 장점. Proxy Task 설정함에 있어 hueristics(인간의 개입)이 많이 필요함.
        1. Exampler(2014 NIPS) :  각각의 이미지 하나 하나에 레이블을 부여하고 classification task를 수행함. 예를 들면, ImageNet classification의 경우 1,000,000개의 레이블에 대해서 학습을 하게 됨. 그런데 각각의 이미지들은 Random한 Augmentation이 적용되어 같은 클래스로 취급함.
        2. Relative Patch Location(2015 ICCV) : 상대적인 위치를 학습하여 Representation을 학습함. 이미지를 9개로 짜른 뒤, 중앙에 있는 이미지과 주변의 8개 이미지 중 하나의 이미지 (총 2개의 이미지를) input으로 넣어 8개의 클래스 중 하나로 classification하게끔 학습함. 
        3. Rotation (2018 ICLR) : 원본 이미지가 있을 때, 0도, 90도, 180도, 270도 돌린 이미지를 Convolution layer로 4개의 레이블로 classification하도록 학습 시킴. Rotation과 Relative Patch Location 모두 상대적인 위치를 고려한 학습이기 때문에 객체가 가진 깊은 특징까지 학습하기는 어려울 수 있음.
        4. Jigsaw Puzzle(2016 ECCV) 샘플 이미지를 9개의 patch로 나눈 뒤 이를 섞은 이미지에 레이블을 부여해서 classification task를 학습시킴.(9개니까 섞을 수 있는 경우의 수는 $9!$로 $362,880$ class.그러나 실제로는 이 중에서 $100$개의 class만을 뽑아 학습을 진행함). 이 역시도 깊은 representation을 학습하기 어려움.

3. Contrastive Learning
    1. Learning by comparing images
        1. No Decoder
        2. No Proxy task
        3. with Contrastive Loss
        4. Premise : Augmentation은 Semantic한 정보를 바꾸지 않는다
        5. **Positive Sample과 Negative Sample을 비교하며 학습**